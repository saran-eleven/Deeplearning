{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "**Implement a simple convolutional neural network for handwritten digit\n",
        "classification using the MNIST dataset. Please implement a normal artificial\n",
        "neural network, then a CNN, and compare the performance.**\n"
      ],
      "metadata": {
        "id": "8mWqRwb3nsDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmAlg9RGwBVp"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "(X_train, y_train), (X_test,y_test) = datasets.mnist.load_data()\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVzWq-PNxme5",
        "outputId": "8122e105-2da1-46da-fc9d-de117d36e745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf2FimqDxqU4",
        "outputId": "8c2e0146-a77d-455a-ea91-e70752657dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yv3JobfRwyD",
        "outputId": "1b15882a-b706-4780-afde-9d77b1da5ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255.\n",
        "#Hence to normalize in 0-->1 range, we need to divide it by 255\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "TBswA0eLSGfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build simple artificial neural network for image classification"
      ],
      "metadata": {
        "id": "iqQZUO0CSTG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28,28,1)),\n",
        "        layers.Dense(3000, activation='relu'),\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "ann.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ann.fit(X_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80QiD3oxSQJt",
        "outputId": "848c6323-3987-4b37-9f2e-542e398833cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 91s 48ms/step - loss: 0.5018 - accuracy: 0.8774\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.2495 - accuracy: 0.9291\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.2002 - accuracy: 0.9434\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.1681 - accuracy: 0.9527\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.1440 - accuracy: 0.9594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x780f61313fd0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import numpy as np\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHMHqGKPSW7_",
        "outputId": "b007b8a4-77f7-4ca4-90f4-7efe5d902ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 20ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.98      0.99      0.99      1135\n",
            "           2       0.97      0.96      0.96      1032\n",
            "           3       0.94      0.97      0.95      1010\n",
            "           4       0.96      0.96      0.96       982\n",
            "           5       0.95      0.95      0.95       892\n",
            "           6       0.96      0.97      0.96       958\n",
            "           7       0.96      0.95      0.96      1028\n",
            "           8       0.98      0.92      0.95       974\n",
            "           9       0.95      0.95      0.95      1009\n",
            "\n",
            "    accuracy                           0.96     10000\n",
            "   macro avg       0.96      0.96      0.96     10000\n",
            "weighted avg       0.96      0.96      0.96     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now let's build a convolutional neural network to train our images"
      ],
      "metadata": {
        "id": "8fNnuo99Sd9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "hkLiA_MvScLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IC896WrfUwdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(X_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ODg8YV-UzJ1",
        "outputId": "b586c6f6-2c61-468e-9374-9f02f54894d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.1356 - accuracy: 0.9582\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0450 - accuracy: 0.9859\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0316 - accuracy: 0.9898\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0243 - accuracy: 0.9923\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0181 - accuracy: 0.9940\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0141 - accuracy: 0.9955\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0109 - accuracy: 0.9964\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0097 - accuracy: 0.9966\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0079 - accuracy: 0.9976\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0075 - accuracy: 0.9976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x780f451e6bc0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With CNN, at the end 5 epochs, accuracy was at around 99% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features**"
      ],
      "metadata": {
        "id": "_vJ-sLVDU-ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1UOQPxiV5XN",
        "outputId": "8dd2c9e4-d6d4-43c8-83e4-ffee302b0c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0442 - accuracy: 0.9893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04422392696142197, 0.989300012588501]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL0FXLp3V7qd",
        "outputId": "8c68aa49-af18-4b12-b031-06810bcdee22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.28992346e-12, 2.20284083e-10, 1.84227833e-09, ...,\n",
              "        9.99999940e-01, 5.56800751e-11, 4.69909745e-12],\n",
              "       [8.52588995e-13, 1.62887079e-10, 9.99999940e-01, ...,\n",
              "        1.53511965e-14, 4.50505146e-15, 2.80538223e-15],\n",
              "       [5.50631318e-10, 9.99998152e-01, 4.96451047e-10, ...,\n",
              "        1.74749289e-07, 6.33934462e-07, 8.67037020e-09],\n",
              "       ...,\n",
              "       [3.29324149e-21, 7.06784674e-13, 4.49270535e-18, ...,\n",
              "        1.41474204e-14, 1.01934317e-09, 9.07711666e-12],\n",
              "       [1.11980807e-11, 1.07145625e-16, 2.65079520e-14, ...,\n",
              "        5.54073420e-16, 1.84006851e-10, 1.45021474e-15],\n",
              "       [3.16923085e-11, 4.14617091e-10, 8.89087581e-10, ...,\n",
              "        5.01517070e-15, 7.11755543e-09, 1.22165444e-10]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_classes = [np.argmax(element) for element in y_pred]\n",
        "y_classes[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilbtz2y4WBuH",
        "outputId": "00e0360e-b2e0-431a-deb4-c75cf3073a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 2, 1, 0, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import numpy as np\n",
        "y_pred = cnn.predict(X_test)\n",
        "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyxvtg-BWDNs",
        "outputId": "44f37ce2-3059-4d63-fe0f-efd56d8bd825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      1.00      0.99      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.98      1.00      0.99      1010\n",
            "           4       1.00      0.99      0.99       982\n",
            "           5       0.98      0.99      0.99       892\n",
            "           6       0.99      0.98      0.99       958\n",
            "           7       0.98      0.99      0.99      1028\n",
            "           8       1.00      0.98      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Report Metrics**\n",
        "\n",
        "**Precision**: The ratio of correctly predicted positive observations to the total predicted positives. High precision relates to the low false positive rate.\n",
        "\n",
        "**Recall**: The ratio of correctly predicted positive observations to all the observations in the actual class. High recall relates to the low false negative rate.\n",
        "\n",
        "**F1-Score**: The weighted average of Precision and Recall. This score is useful when the class distribution is imbalanced.\n",
        "\n",
        "**Support**: The number of actual occurrences of the class in the dataset."
      ],
      "metadata": {
        "id": "p6USUvbBm4h4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Comparing both ANN and CNN**\n",
        "\n",
        "**CNN Performance:**\n",
        "\n",
        "**Higher Accuracy:** CNN achieves 99% accuracy compared to 96% with ANN.\n",
        "\n",
        "**Better Precision and Recall:** CNN has better precision and recall for all classes, meaning it makes fewer errors in classification.\n",
        "\n",
        "Higher F1-Scores: CNN consistently has higher F1-scores, indicating a better balance between precision and recall.\n",
        "\n",
        "**Implications:**\n",
        "\n",
        "CNN models are more suited for image data as they can capture spatial hierarchies through convolutional and pooling layers.\n",
        "\n",
        "ANN models may not perform as well on image data due to the lack of convolutional layers to extract spatial features."
      ],
      "metadata": {
        "id": "DXleI0x8meZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "onuil3MZnkoa"
      }
    }
  ]
}